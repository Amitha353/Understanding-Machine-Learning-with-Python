Machine Learning
------------------
Building a model from example inputs to make data-driven predictions versus following strictly static program instructions.
Application:

1. Email a spam?
2. How can cars drive themselves?
3. What will people buy?

Machine Learning
-----------------
2 categories
a. Supervised;
  - Value Prediction
  - Needs training data containing value being predicted, the trained model predicts value in the new model;
b. Unsupervised;
   - Identify clusters of like data;
   - Data does not contain cluster membership, but model provides access to data by cluster;

url -> https://www.continuum.io/downloads


Machine Learning WorkFlow:
--------------------------   
An orchestrated and repeatable pattern which systematically transforms and processes information to create prediction solutions.

1. Asking the right question;
2. Preparing data;
3. Selecting the algorithm;
4. Training the model;
5. Testing the model;

------------------------------------------------------------------------------------------------------------------------

1. Asking the Right Question
-----------------------------
a. Define scope (including data sources);
 - Using Pima Indian Diabetes data, predict which people will develop diabetes.
 
b. Define target performance;
 - Using Pima Indian Diabetes data, predict with 70% or grater accuracy, which people will develop diabetes.
 
c. Define context for usage;
 - Using Pima Indian Diabetes data, predict with 70% or greater accuracy which people are likely to develop diabetes.
 
d. Define how solution is created;
 - Use the Machine Learning Workflow to process and transform Pima Indian data to create a predictin model. This model 
 must predict whih people are likely to develop diabetes with 70% or greater accuracy.
 
---------------------------------------------------------------------------------------------------------------------------

2. Preparing data
 ---------------------
 a. Tidy Data
 - Tidy datasets are easy to manipulate, model and visualize,and have a specific structure:
 * each variable is a column;
 * each observation is a row;
 * each type of observational unit is a table;
 ** 50 - 80% of a ML project is spent getting, cleaning, and organizing data;
 
Data Rule #1:
---------------
- Closer the data is to what you are predicting, the better;

Data Rule #2:
--------------
- Data will never be in the format you need;
* Columns to eliminate - Not used, no values, duplicates;
* Correlated columns - Same information in different format, add little value, and cause algorithm to get confused;
* Modling Data - Adjusting data types, creating columns, if required;
* Dealing with missing data - 
  - Ignore it - Algorithms may fail;
  - Impute it - update to "reasonable" values - Most frequent, Mean, Median, Expert reasonable value;

Data Rule #3:
----------------
Accurately predicting rare events is difficule;

Data Rule #4:
--------------
Track how to manipulate data;

-------------------------------------------------------------------------------------------------------------------------

3.  Selecting the algorithm:
------------------------------
Role of the Algorithm
 - fit the training set and predict on the read data;
 - (fit()) training data -> Algorithm -> model;
 - (predict()) real data -> Model -> result;
 
 Over 50 algorithms
 - algorithm selection 
 *. Compare factors;
 *. Difference of opinions about which factors are important;
 *. Develop your own factors;
 
Algorithm Decision Factors
--------------------------
i. Learning Type
ii. Result
iii. Complexity
iv. Basic vs Enhanced

i. Learning Type:
"Use the Machine Learning Workflow to process and transform Pima Indian data to create a "prediction model". This model must 
predict which people are likely to develop diabetes with 70% or greater accuracy."

-> Prediction Model => Supervised machine learning;
Over 28 algorithms

ii. Result
a. Regression - constinuous vales;
b. Classification - discrete values;

"Use the Machine Learning Workflow to process and transform Pima Indian data to create a prediction model. This model must 
"predict which people are likely to develop diabetes" with 70% or greater accuracy."

- Diabetes
- Binary (True/False)
- Algorithm must support classification - Binary classification;
** Over 20 algorithms;

iii. Complexity
- Keep it simple;
- Eliminate ensemble algorithms - Container algorithm; Multiple child algorithm, boost performance, Can be difficult to debug;
** Over 14 algorithm;

iv. Enhanced vs. Basic 
- Enhanced - variation of basic, performance improvements, additional functionality, more complex;
- Basic - simpler, easier to understand;

Candidate Algorithms
--------------------
a. Naive Bayes;
b. Logistics Regression;
c. Decision Tree;

a. Naive Bayes - Based on likelihood and probability; every feature has same weight; requires smaller amount of data;
b. Logistic Regression - Binary result, relation between features are weighted;
c. Decision Tree - Binary tree, node contains decision, requires enough data to determine nodes and splits;

Selected algorithm - Naive Bayes
-------------------------------
Simple - easy to understand;
Fast - up to 100X faster;
Stable to data changes;

Overview
----------
Lots of algorithms available

Selected based on
- Learning = Supervised
- Result = Binary classification
- Non-ensemble 
- Basic




 
